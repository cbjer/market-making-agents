{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "7acc00d4b52606d008ddb36073f9ec969f123fca1114370a8a51dabb8e431f68"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Source.Agents.DeepQNetwork import DQNMarketMaker\n",
    "\n",
    "import gym\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_EPISODES = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "env = env.unwrapped\n",
    "\n",
    "numberActions = env.action_space.n\n",
    "stateSpaceSize = env.observation_space.shape[0]\n",
    "actionSpace = list(range(numberActions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = DQNMarketMaker(actionSpace, stateSpaceSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Episode: 0 episodeReturn: 17.0 Epsilon 0.99\n",
      "Episode: 10 episodeReturn: 27.0 Epsilon 0.9700076160462067\n",
      "Episode: 20 episodeReturn: 27.0 Epsilon 0.9556609334442919\n",
      "Episode: 30 episodeReturn: 18.0 Epsilon 0.9356131763630244\n",
      "Episode: 40 episodeReturn: 20.0 Epsilon 0.9076879052564795\n",
      "Episode: 50 episodeReturn: 23.0 Epsilon 0.886338926278323\n",
      "Episode: 60 episodeReturn: 37.0 Epsilon 0.8655786368996335\n",
      "Episode: 70 episodeReturn: 45.0 Epsilon 0.8382334340197369\n",
      "Episode: 80 episodeReturn: 20.0 Epsilon 0.8128894215727717\n",
      "Episode: 90 episodeReturn: 53.0 Epsilon 0.7955184236924547\n",
      "Episode: 100 episodeReturn: 13.0 Epsilon 0.7782072736949314\n",
      "Episode: 110 episodeReturn: 44.0 Epsilon 0.7595997860263816\n",
      "Episode: 120 episodeReturn: 27.0 Epsilon 0.7447813699674796\n",
      "Episode: 130 episodeReturn: 13.0 Epsilon 0.7261738486402544\n",
      "Episode: 140 episodeReturn: 17.0 Epsilon 0.7112958248854813\n",
      "Episode: 150 episodeReturn: 12.0 Epsilon 0.7003552014416313\n",
      "Episode: 160 episodeReturn: 9.0 Epsilon 0.6841563455693194\n",
      "Episode: 170 episodeReturn: 16.0 Epsilon 0.6708096943926267\n",
      "Episode: 180 episodeReturn: 14.0 Epsilon 0.6522214012390951\n",
      "Episode: 190 episodeReturn: 15.0 Epsilon 0.6361172022654857\n",
      "Episode: 200 episodeReturn: 25.0 Epsilon 0.619728526438561\n",
      "Episode: 210 episodeReturn: 17.0 Epsilon 0.6035809715597711\n",
      "Episode: 220 episodeReturn: 15.0 Epsilon 0.5935843734306728\n",
      "Episode: 230 episodeReturn: 22.0 Epsilon 0.5813065958430815\n",
      "Episode: 240 episodeReturn: 21.0 Epsilon 0.5687706238268031\n",
      "Episode: 250 episodeReturn: 13.0 Epsilon 0.5585121210957893\n",
      "Episode: 260 episodeReturn: 26.0 Epsilon 0.5500315037708959\n",
      "Episode: 270 episodeReturn: 41.0 Epsilon 0.5388700952003476\n",
      "Episode: 280 episodeReturn: 10.0 Epsilon 0.5268276214574827\n",
      "Episode: 290 episodeReturn: 16.0 Epsilon 0.5171187149952154\n",
      "Episode: 300 episodeReturn: 14.0 Epsilon 0.5072842568620879\n",
      "Episode: 310 episodeReturn: 38.0 Epsilon 0.49788572152284105\n",
      "Episode: 320 episodeReturn: 38.0 Epsilon 0.4847189486974898\n",
      "Episode: 330 episodeReturn: 56.0 Epsilon 0.4742184785322375\n",
      "Episode: 340 episodeReturn: 11.0 Epsilon 0.4632500488412485\n",
      "Episode: 350 episodeReturn: 32.0 Epsilon 0.4533053161423039\n",
      "Episode: 360 episodeReturn: 9.0 Epsilon 0.4458421900643004\n",
      "Episode: 370 episodeReturn: 45.0 Epsilon 0.43492074339082065\n",
      "Episode: 380 episodeReturn: 12.0 Epsilon 0.42724726703225824\n",
      "Episode: 390 episodeReturn: 30.0 Epsilon 0.4186611620315751\n",
      "Episode: 400 episodeReturn: 11.0 Epsilon 0.4106170138140927\n",
      "Episode: 410 episodeReturn: 12.0 Epsilon 0.4009191335963139\n",
      "Episode: 420 episodeReturn: 13.0 Epsilon 0.39518698200779806\n",
      "Episode: 430 episodeReturn: 20.0 Epsilon 0.386200967430828\n",
      "Episode: 440 episodeReturn: 18.0 Epsilon 0.37836405852963945\n",
      "Episode: 450 episodeReturn: 34.0 Epsilon 0.3710941781514089\n",
      "Episode: 460 episodeReturn: 22.0 Epsilon 0.36418243596863864\n",
      "Episode: 470 episodeReturn: 11.0 Epsilon 0.3582940882528085\n",
      "Episode: 480 episodeReturn: 12.0 Epsilon 0.35130441952350366\n",
      "Episode: 490 episodeReturn: 10.0 Epsilon 0.3454860632988575\n",
      "Episode: 500 episodeReturn: 14.0 Epsilon 0.34020607419131826\n",
      "Episode: 510 episodeReturn: 11.0 Epsilon 0.3337027309273755\n",
      "Episode: 520 episodeReturn: 10.0 Epsilon 0.328668554375206\n",
      "Episode: 530 episodeReturn: 10.0 Epsilon 0.32196691099674485\n",
      "Episode: 540 episodeReturn: 12.0 Epsilon 0.31752231024052824\n",
      "Episode: 550 episodeReturn: 12.0 Epsilon 0.31210735784549937\n",
      "Episode: 560 episodeReturn: 46.0 Epsilon 0.306478104067789\n",
      "Episode: 570 episodeReturn: 18.0 Epsilon 0.3029736200511643\n",
      "Episode: 580 episodeReturn: 18.0 Epsilon 0.2978961375746529\n",
      "Episode: 590 episodeReturn: 15.0 Epsilon 0.29443089072555667\n",
      "Episode: 600 episodeReturn: 20.0 Epsilon 0.2894676247142726\n",
      "Episode: 610 episodeReturn: 10.0 Epsilon 0.28544311405077694\n",
      "Episode: 620 episodeReturn: 12.0 Epsilon 0.2797906818876452\n",
      "Episode: 630 episodeReturn: 28.0 Epsilon 0.2746893544148745\n",
      "Episode: 640 episodeReturn: 9.0 Epsilon 0.27138547680135994\n",
      "Episode: 650 episodeReturn: 15.0 Epsilon 0.26633083957384196\n",
      "Episode: 660 episodeReturn: 12.0 Epsilon 0.26291706722624336\n",
      "Episode: 670 episodeReturn: 12.0 Epsilon 0.2593135529587006\n",
      "Episode: 680 episodeReturn: 9.0 Epsilon 0.2560153282389416\n",
      "Episode: 690 episodeReturn: 10.0 Epsilon 0.25127209192262767\n",
      "Episode: 700 episodeReturn: 12.0 Epsilon 0.2478281824882534\n",
      "Episode: 710 episodeReturn: 13.0 Epsilon 0.24352870448097785\n",
      "Episode: 720 episodeReturn: 10.0 Epsilon 0.23937562200753365\n",
      "Episode: 730 episodeReturn: 19.0 Epsilon 0.23576444645580102\n",
      "Episode: 740 episodeReturn: 52.0 Epsilon 0.23139640141639967\n",
      "Episode: 750 episodeReturn: 12.0 Epsilon 0.2279511868416261\n",
      "Episode: 760 episodeReturn: 12.0 Epsilon 0.2243776844246935\n",
      "Episode: 770 episodeReturn: 20.0 Epsilon 0.22086020242029208\n",
      "Episode: 780 episodeReturn: 15.0 Epsilon 0.2178549007039277\n",
      "Episode: 790 episodeReturn: 18.0 Epsilon 0.21358358566944832\n",
      "Episode: 800 episodeReturn: 18.0 Epsilon 0.21052986887899788\n",
      "Episode: 810 episodeReturn: 11.0 Epsilon 0.20743681720791401\n",
      "Episode: 820 episodeReturn: 23.0 Epsilon 0.20404202404793803\n",
      "Episode: 830 episodeReturn: 10.0 Epsilon 0.20170886548781602\n",
      "Episode: 840 episodeReturn: 12.0 Epsilon 0.1979717735617757\n",
      "Episode: 850 episodeReturn: 12.0 Epsilon 0.19547330596439827\n",
      "Episode: 860 episodeReturn: 11.0 Epsilon 0.19254368685300657\n",
      "Episode: 870 episodeReturn: 23.0 Epsilon 0.18935474957622256\n",
      "Episode: 880 episodeReturn: 11.0 Epsilon 0.18653548471709175\n",
      "Episode: 890 episodeReturn: 12.0 Epsilon 0.18427346507838932\n",
      "Episode: 900 episodeReturn: 10.0 Epsilon 0.18185691880533406\n",
      "Episode: 910 episodeReturn: 28.0 Epsilon 0.17904182493980966\n",
      "Episode: 920 episodeReturn: 18.0 Epsilon 0.17619981038651983\n",
      "Episode: 930 episodeReturn: 10.0 Epsilon 0.17340290845830428\n",
      "Episode: 940 episodeReturn: 33.0 Epsilon 0.16978225824887608\n",
      "Episode: 950 episodeReturn: 12.0 Epsilon 0.16742175071553964\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-63095fb269d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mnextState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mepisodeReturn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputPostTrade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactionIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnextState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/MarketMakingAgents/Source/Agents/DeepQNetwork.py\u001b[0m in \u001b[0;36minputPostTrade\u001b[0;34m(self, state, actionIndex, reward, done, nextState)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minputPostTrade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactionIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deepQNetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoreExperience\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactionIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deepQNetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/MarketMakingAgents/Source/Agents/DeepQNetwork.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, batchSize)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactionIndexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextStates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampleExperience\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mqActionValues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluationNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactionIndexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mnextStateQValues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targetNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnextStates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mnextStateMaxActionValue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnextStateQValues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/cbenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/MarketMakingAgents/Source/Agents/DeepQNetwork.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfullConnected1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfullConnected2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/cbenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/cbenv/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/cbenv/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for episodeNumber in range(NUMBER_EPISODES):\n",
    "    state = env.reset()\n",
    "    episodeReturn = 0.0\n",
    "    episodeCounter = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        episodeCounter += 1\n",
    "\n",
    "        action, actionIndex = dqn.getSkewAction(state)\n",
    "        nextState, reward, done, _ = env.step(action)\n",
    "        episodeReturn += reward\n",
    "        dqn.inputPostTrade(state, actionIndex, reward, done, nextState)\n",
    "        state = nextState\n",
    "\n",
    "    if episodeNumber % 10 == 0:\n",
    "        print(\"Episode:\", episodeNumber, \"episodeReturn:\", episodeReturn, \"Epsilon\", dqn._deepQNetwork._epsilon)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}