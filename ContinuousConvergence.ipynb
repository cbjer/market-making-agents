{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd07acc00d4b52606d008ddb36073f9ec969f123fca1114370a8a51dabb8e431f68",
   "display_name": "Python 3.7.9 64-bit ('cbenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Classic cart-pole system implemented by Rich Sutton et al.\n",
    "Copied from http://incompleteideas.net/sutton/book/code/pole.c\n",
    "permalink: https://perma.cc/C9ZM-652R\n",
    "Continuous version by Ian Danforth\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import gym\n",
    "from gym import spaces, logger\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ContinuousCartPoleEnv(gym.Env):\n",
    "    metadata = {\n",
    "        'render.modes': ['human', 'rgb_array'],\n",
    "        'video.frames_per_second': 50\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        self.gravity = 9.8\n",
    "        self.masscart = 1.0\n",
    "        self.masspole = 0.1\n",
    "        self.total_mass = (self.masspole + self.masscart)\n",
    "        self.length = 0.5  # actually half the pole's length\n",
    "        self.polemass_length = (self.masspole * self.length)\n",
    "        self.force_mag = 30.0\n",
    "        self.tau = 0.02  # seconds between state updates\n",
    "        self.min_action = -1.0\n",
    "        self.max_action = 1.0\n",
    "\n",
    "        # Angle at which to fail the episode\n",
    "        self.theta_threshold_radians = 12 * 2 * math.pi / 360\n",
    "        self.x_threshold = 2.4\n",
    "\n",
    "        # Angle limit set to 2 * theta_threshold_radians so failing observation\n",
    "        # is still within bounds\n",
    "        high = np.array([\n",
    "            self.x_threshold * 2,\n",
    "            np.finfo(np.float32).max,\n",
    "            self.theta_threshold_radians * 2,\n",
    "            np.finfo(np.float32).max])\n",
    "\n",
    "        self.action_space = spaces.Box(\n",
    "            low=self.min_action,\n",
    "            high=self.max_action,\n",
    "            shape=(1,)\n",
    "        )\n",
    "        self.observation_space = spaces.Box(-high, high)\n",
    "\n",
    "        self.seed()\n",
    "        self.viewer = None\n",
    "        self.state = None\n",
    "\n",
    "        self.steps_beyond_done = None\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def stepPhysics(self, force):\n",
    "        x, x_dot, theta, theta_dot = self.state\n",
    "        costheta = math.cos(theta)\n",
    "        sintheta = math.sin(theta)\n",
    "        temp = (force + self.polemass_length * theta_dot * theta_dot * sintheta) / self.total_mass\n",
    "        thetaacc = (self.gravity * sintheta - costheta * temp) / \\\n",
    "            (self.length * (4.0/3.0 - self.masspole * costheta * costheta / self.total_mass))\n",
    "        xacc = temp - self.polemass_length * thetaacc * costheta / self.total_mass\n",
    "        x = x + self.tau * x_dot\n",
    "        x_dot = x_dot + self.tau * xacc\n",
    "        theta = theta + self.tau * theta_dot\n",
    "        theta_dot = theta_dot + self.tau * thetaacc\n",
    "        return (x, x_dot, theta, theta_dot)\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action), \\\n",
    "            \"%r (%s) invalid\" % (action, type(action))\n",
    "        # Cast action to float to strip np trappings\n",
    "        force = self.force_mag * float(action)\n",
    "        self.state = self.stepPhysics(force)\n",
    "        x, x_dot, theta, theta_dot = self.state\n",
    "        done = x < -self.x_threshold \\\n",
    "            or x > self.x_threshold \\\n",
    "            or theta < -self.theta_threshold_radians \\\n",
    "            or theta > self.theta_threshold_radians\n",
    "        done = bool(done)\n",
    "\n",
    "        if not done:\n",
    "            reward = 1.0\n",
    "        elif self.steps_beyond_done is None:\n",
    "            # Pole just fell!\n",
    "            self.steps_beyond_done = 0\n",
    "            reward = 1.0\n",
    "        else:\n",
    "            if self.steps_beyond_done == 0:\n",
    "                logger.warn(\"\"\"\n",
    "You are calling 'step()' even though this environment has already returned\n",
    "done = True. You should always call 'reset()' once you receive 'done = True'\n",
    "Any further steps are undefined behavior.\n",
    "                \"\"\")\n",
    "            self.steps_beyond_done += 1\n",
    "            reward = 0.0\n",
    "\n",
    "        return np.array(self.state), reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self.np_random.uniform(low=-0.05, high=0.05, size=(4,))\n",
    "        self.steps_beyond_done = None\n",
    "        return np.array(self.state)\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        screen_width = 600\n",
    "        screen_height = 400\n",
    "\n",
    "        world_width = self.x_threshold * 2\n",
    "        scale = screen_width /world_width\n",
    "        carty = 100  # TOP OF CART\n",
    "        polewidth = 10.0\n",
    "        polelen = scale * 1.0\n",
    "        cartwidth = 50.0\n",
    "        cartheight = 30.0\n",
    "\n",
    "        if self.viewer is None:\n",
    "            from gym.envs.classic_control import rendering\n",
    "            self.viewer = rendering.Viewer(screen_width, screen_height)\n",
    "            l, r, t, b = -cartwidth / 2, cartwidth / 2, cartheight / 2, -cartheight / 2\n",
    "            axleoffset = cartheight / 4.0\n",
    "            cart = rendering.FilledPolygon([(l, b), (l, t), (r, t), (r, b)])\n",
    "            self.carttrans = rendering.Transform()\n",
    "            cart.add_attr(self.carttrans)\n",
    "            self.viewer.add_geom(cart)\n",
    "            l, r, t, b = -polewidth / 2, polewidth / 2, polelen-polewidth / 2, -polewidth / 2\n",
    "            pole = rendering.FilledPolygon([(l, b), (l, t), (r, t), (r, b)])\n",
    "            pole.set_color(.8, .6, .4)\n",
    "            self.poletrans = rendering.Transform(translation=(0, axleoffset))\n",
    "            pole.add_attr(self.poletrans)\n",
    "            pole.add_attr(self.carttrans)\n",
    "            self.viewer.add_geom(pole)\n",
    "            self.axle = rendering.make_circle(polewidth / 2)\n",
    "            self.axle.add_attr(self.poletrans)\n",
    "            self.axle.add_attr(self.carttrans)\n",
    "            self.axle.set_color(.5, .5, .8)\n",
    "            self.viewer.add_geom(self.axle)\n",
    "            self.track = rendering.Line((0, carty), (screen_width, carty))\n",
    "            self.track.set_color(0, 0, 0)\n",
    "            self.viewer.add_geom(self.track)\n",
    "\n",
    "        if self.state is None:\n",
    "            return None\n",
    "\n",
    "        x = self.state\n",
    "        cartx = x[0] * scale + screen_width / 2.0  # MIDDLE OF CART\n",
    "        self.carttrans.set_translation(cartx, carty)\n",
    "        self.poletrans.set_rotation(-x[2])\n",
    "\n",
    "        return self.viewer.render(return_rgb_array=(mode == 'rgb_array'))\n",
    "\n",
    "    def close(self):\n",
    "        if self.viewer:\n",
    "            self.viewer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Source.Agents.DeepDeterministicPolicyGradient import DDPGMarketMaker\n",
    "from Source.Agents.Utils.DataPlotter import DataPlotter\n",
    "\n",
    "NUMBER_EPISODES = 10000\n",
    "\n",
    "env = ContinuousCartPoleEnv()\n",
    "\n",
    "ACTION_DIM = 1\n",
    "stateSpaceSize = env.observation_space.shape[0]\n",
    "\n",
    "ddpg = DDPGMarketMaker(ACTION_DIM, stateSpaceSize, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevMax = 0.0\n",
    "dataPlotter = DataPlotter()\n",
    "\n",
    "for episodeNumber in range(NUMBER_EPISODES):\n",
    "    state = env.reset()\n",
    "    episodeReturn = 0.0\n",
    "    episodeCounter = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        episodeCounter += 1\n",
    "\n",
    "        action = ddpg.getSkewAction(state)\n",
    "        nextState, reward, done, _ = env.step(np.array(action).reshape(1))\n",
    "        episodeReturn += reward\n",
    "        ddpg.inputPostTrade(state, action, reward, done, nextState)\n",
    "        state = nextState\n",
    "    \n",
    "    dataPlotter.add(\"episodeReturn\", episodeReturn)\n",
    "    newMean = np.mean(dataPlotter.get(\"episodeReturn\")[-10:])\n",
    "\n",
    "    if newMean > prevMax:\n",
    "        prevMax = newMean\n",
    "        print(\"New Max Found. Episode: {} EpisodeReturn: {} runningMean: {}\".format(episodeNumber, episodeReturn, newMean))\n",
    "    \n",
    "    if newMean > 199:\n",
    "        print(\"Environment Solved!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.22312848666887095"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "1.00 * np.power(0.99999, 5000*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}